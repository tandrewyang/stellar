# 针对fkwz地图的优化配置 - "反客为主"策略
# fkwz特点: 5 agents vs 7 enemies, 300步, P vs P，有建造机制（warpgateTrain, WarpPrism）
# 优化方向: 主动进攻 + 建造奖励 + 资源管理
# 战术核心: 从被动转为主动，通过建造、训练、资源管理来获得优势

action_selector: "epsilon_greedy"
epsilon_start: 0.995
epsilon_finish: 0.05
epsilon_anneal_time: 150000  # 更长的探索时间（300步需要更多探索）

runner: "episode"
batch_size_run: 1
buffer_size: 5000

batch_size: 128

critic_mac: "cate_broadcast_comm_mac_full"
critic_agent: "rnn_agent_n"

comm: True
comm_embed_dim: 3
comm_method: "information_bottleneck_full"
c_beta: 1.
comm_beta: 0.001
comm_entropy_beta: 1e-6
gate_loss_beta: 0.00001
only_downstream: False
use_IB: True
is_print: False

target_update_interval: 200
t_max: 2005000

mac: "basic_mac_logits"
agent: "rnn"
agent_output_type: "q"
learner: "reward_shaping_learner"
double_q: True
mixer: "qmix"
mixing_embed_dim: 64
hypernet_layers: 2
hypernet_embed: 128

# 针对fkwz的"反客为主"奖励塑形（主动进攻 - 优化版）
# 战术核心：从被动转为主动，通过建造、训练、资源管理来获得优势
# 5 vs 7，300步，需要强烈的生存奖励和主动进攻奖励
# 重新设计：更精确的检测机制，更强的奖励信号，新增敌方单位消灭奖励
# 当前问题：测试奖励为负（-1.1640），需要大幅增强生存奖励
reward_shaping_enabled: True
reward_shaping_type: "potential_based"  # 代码会根据map_name自动识别
reward_shaping_weight: 0.6  # 大幅增加塑形权重（从0.5增加到0.6）
reward_shaping_decay: 0.9999  # 更慢的衰减（从0.9998增加到0.9999）
warpgate_train_reward_weight: 6.0  # 大幅增加折跃门训练奖励权重（从5.0增加到6.0）
warp_prism_reward_weight: 5.0  # 大幅增加折跃棱镜奖励权重（从4.0增加到5.0）
resource_management_weight: 4.5  # 大幅增加资源管理奖励权重（从3.5增加到4.5）
active_offensive_weight: 6.5  # 大幅增加主动进攻奖励权重（从5.0增加到6.5）
unit_advantage_weight: 4.5  # 大幅增加单位优势奖励权重（从3.5增加到4.5）
damage_reward_factor: 2.2  # 大幅增加伤害奖励放大因子（从1.8增加到2.2，220%）
passive_to_active_conversion_weight: 5.0  # 从被动到主动的转换奖励权重（从4.0增加到5.0）

central_loss: 1
qmix_loss: 1
w: 0.5
hysteretic_qmix: True

central_mixing_embed_dim: 256
central_action_embed: 1
central_mac: "basic_central_mac"
central_agent: "central_rnn"
central_rnn_hidden_dim: 64
central_mixer: "ff"
td_lambda: 0.6
lr: 0.001  # 标准学习率（长期规划需要稳定）

alpha_lr: 3e-4
alpha_init: -0.07

p: 0.5
name: "targeted_qmix_fkwz_active_offensive"


{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/CurriculumLearning/src",
    "dependencies": [
      "numpy==1.26.4",
      "pyyaml==6.0.3",
      "sacred==0.8.7",
      "torch==2.1.2+cu118"
    ],
    "mainfile": "main.py",
    "name": "pymarl",
    "repositories": [
      {
        "commit": "ef65acb6db201cca6158afae4e1b05782e9b3ab0",
        "dirty": true,
        "url": "https://github.com/tandrewyang/stellar"
      },
      {
        "commit": "ef65acb6db201cca6158afae4e1b05782e9b3ab0",
        "dirty": true,
        "url": "https://github.com/tandrewyang/stellar"
      }
    ],
    "sources": [
      [
        "main.py",
        "_sources/main_3992b8ec14bf1a440a6c16ee0a45870f.py"
      ],
      [
        "utils/logging.py",
        "_sources/logging_600053ef114d259d30892ef0975f7420.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/sacred/config/captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/CurriculumLearning/src/main.py\", line 53, in my_main\n    run_REGISTRY[_config['run']](_run, config, _log)\n",
    "  File \"/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/CurriculumLearning/src/run/run.py\", line 54, in run\n    run_sequential(args=args, logger=logger)\n",
    "  File \"/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/CurriculumLearning/src/run/run.py\", line 197, in run_sequential\n    learner.train(episode_sample, runner.t_env, episode)\n",
    "  File \"/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/CurriculumLearning/src/learners/curriculum_learner.py\", line 107, in train\n    return super(CurriculumLearner, self).train(batch, t_env, episode_num)\n",
    "  File \"/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/CurriculumLearning/src/learners/max_q_learner.py\", line 215, in train\n    Q_i_mean_negi_mean = self.mixer(q_i_mean_negi_mean.view(-1, self.n_agents, 1), batch[\"state\"],dropout=True).view(q_i_mean_negi_mean.shape[0],q_i_mean_negi_mean.shape[1],self.n_agents)[:,:-1]\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n",
    "  File \"/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/CurriculumLearning/src/modules/mixers/qmix.py\", line 57, in forward\n    w_final = self.hyper_w_final(states).abs() if self.abs else self.hyper_w_final(states)\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/nn/modules/container.py\", line 215, in forward\n    input = module(input)\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n",
    "  File \"/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n    return F.linear(input, self.weight, self.bias)\n",
    "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 170.00 MiB. GPU 0 has a total capacty of 79.11 GiB of which 129.75 MiB is free. Process 2527129 has 16.61 GiB memory in use. Process 2530213 has 12.37 GiB memory in use. Process 2530981 has 11.69 GiB memory in use. Process 2531680 has 930.00 MiB memory in use. Process 2534566 has 1.60 GiB memory in use. Process 2535016 has 4.12 GiB memory in use. Process 2535853 has 18.25 GiB memory in use. Process 2539023 has 6.19 GiB memory in use. Process 2539522 has 946.00 MiB memory in use. Process 2540176 has 4.43 GiB memory in use. Process 2542937 has 936.00 MiB memory in use. Process 2543493 has 944.00 MiB memory in use. Of the allocated memory 16.59 GiB is allocated by PyTorch, and 577.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
  ],
  "heartbeat": "2025-11-26T08:37:52.448847",
  "host": {
    "ENV": {},
    "cpu": "Intel(R) Xeon(R) Platinum 8468",
    "gpus": {
      "driver_version": "535.161.08",
      "gpus": [
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        }
      ]
    },
    "hostname": "job-fcea379b-ab9f-4368-a257-c64368c4bfa2-master-0",
    "os": [
      "Linux",
      "Linux-5.15.0-105-generic-x86_64-with-glibc2.35"
    ],
    "python_version": "3.10.19"
  },
  "meta": {
    "command": "my_main",
    "config_updates": {
      "batch_size_run": 1,
      "env_args": {
        "map_name": "sdjx"
      },
      "save_model": true,
      "save_model_interval": 500000,
      "seed": 42,
      "t_max": 2005000,
      "use_tensorboard": false
    },
    "named_configs": [],
    "options": {
      "--beat-interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--id": null,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print-config": false,
      "--priority": null,
      "--queue": false,
      "--s3": null,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "env_args.map_name=sdjx",
        "seed=42",
        "t_max=2005000",
        "batch_size_run=1",
        "use_tensorboard=False",
        "save_model=True",
        "save_model_interval=500000"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2025-11-26T08:15:03.760227",
  "status": "FAILED",
  "stop_time": "2025-11-26T08:37:52.463946"
}
{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/EnhancedStateRepresentation/src",
    "dependencies": [
      "numpy==1.26.4",
      "pyyaml==6.0.3",
      "sacred==0.8.7",
      "torch==2.1.2+cu118"
    ],
    "mainfile": "main.py",
    "name": "pymarl",
    "repositories": [
      {
        "commit": "ef65acb6db201cca6158afae4e1b05782e9b3ab0",
        "dirty": true,
        "url": "https://github.com/tandrewyang/stellar"
      },
      {
        "commit": "ef65acb6db201cca6158afae4e1b05782e9b3ab0",
        "dirty": true,
        "url": "https://github.com/tandrewyang/stellar"
      }
    ],
    "sources": [
      [
        "main.py",
        "_sources/main_6e069337b58effbf69eb61ed140253b1.py"
      ],
      [
        "utils/logging.py",
        "_sources/logging_4fe6e0fd5698271a6b6badf6e9ebed89.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/share/project/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/sacred/config/captured_function.py\", line 42, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/EnhancedStateRepresentation/src/main.py\", line 53, in my_main\n    run_REGISTRY[_config['run']](_run, config, _log)\n",
    "  File \"/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/EnhancedStateRepresentation/src/run/run.py\", line 43, in run\n    unique_token = \"{}__{}\".format(args.name, datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "AttributeError: 'types.SimpleNamespace' object has no attribute 'name'\n"
  ],
  "heartbeat": "2025-12-04T11:55:03.488278",
  "host": {
    "ENV": {},
    "cpu": "Intel(R) Xeon(R) Platinum 8468",
    "gpus": {
      "driver_version": "535.161.08",
      "gpus": [
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        },
        {
          "model": "NVIDIA H100 80GB HBM3",
          "persistence_mode": true,
          "total_memory": 81559
        }
      ]
    },
    "hostname": "job-fcea379b-ab9f-4368-a257-c64368c4bfa2-master-0",
    "os": [
      "Linux",
      "Linux-5.15.0-105-generic-x86_64-with-glibc2.35"
    ],
    "python_version": "3.10.19"
  },
  "meta": {
    "command": "my_main",
    "config_updates": {
      "batch_size_run": 1,
      "env_args": {
        "map_name": "fkwz"
      },
      "save_model": true,
      "save_model_interval": 500000,
      "seed": 42,
      "t_max": 2005000,
      "use_tensorboard": false
    },
    "named_configs": [],
    "options": {
      "--beat-interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--id": null,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print-config": false,
      "--priority": null,
      "--queue": false,
      "--s3": null,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "env_args.map_name=fkwz",
        "seed=42",
        "t_max=2005000",
        "batch_size_run=1",
        "use_tensorboard=False",
        "save_model=True",
        "save_model_interval=500000"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2025-12-04T11:55:03.474942",
  "status": "FAILED",
  "stop_time": "2025-12-04T11:55:03.491487"
}
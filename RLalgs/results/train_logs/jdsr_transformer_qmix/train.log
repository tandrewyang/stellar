/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/sacred/dependencies.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[DEBUG 14:22:53] git.cmd Popen(['git', 'version'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:22:53] git.cmd Popen(['git', 'version'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:22:53] git.util sys.platform='linux', git_executable='git'
[DEBUG 14:22:53] git.cmd Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:22:53] git.cmd Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:22:53] git.cmd Popen(['git', 'cat-file', '--batch-check'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=<valid stream>, shell=False, universal_newlines=False)
[DEBUG 14:22:53] git.util sys.platform='linux', git_executable='git'
[DEBUG 14:22:53] git.cmd Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:22:53] git.cmd Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:22:53] git.cmd Popen(['git', 'cat-file', '--batch-check'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=<valid stream>, shell=False, universal_newlines=False)
[INFO 14:22:54] root Saving to FileStorageObserver in /share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/results/sacred/jdsr/transformer_qmix_env=4_adam_td_lambda.
[DEBUG 14:22:56] pymarl Using capture mode "fd"
[INFO 14:22:56] pymarl Running command 'my_main'
[INFO 14:22:56] pymarl Started run with ID "8"
[DEBUG 14:22:56] pymarl Starting Heartbeat
[DEBUG 14:22:56] my_main Started
[INFO 14:22:56] my_main Experiment Parameters:
[INFO 14:22:56] my_main 

{   'action_selector': 'epsilon_greedy',
    'agent': 'rnn',
    'agent_output_type': 'q',
    'alpha_init': -0.07,
    'alpha_lr': '3e-4',
    'batch_size': 128,
    'batch_size_run': 1,
    'buffer_cpu_only': True,
    'buffer_size': 5000,
    'c_beta': 1.0,
    'central_action_embed': 1,
    'central_agent': 'central_rnn',
    'central_loss': 1,
    'central_mac': 'basic_central_mac',
    'central_mixer': 'ff',
    'central_mixing_embed_dim': 256,
    'central_rnn_hidden_dim': 64,
    'checkpoint_path': '',
    'comm': True,
    'comm_beta': 0.001,
    'comm_beta_end_decay': 50000000,
    'comm_beta_start_decay': 20000000,
    'comm_beta_target': '1e-2',
    'comm_embed_dim': 3,
    'comm_entropy_beta': '1e-6',
    'comm_entropy_beta_end_decay': 50000000,
    'comm_entropy_beta_start_decay': 20000000,
    'comm_entropy_beta_target': '1e-4',
    'comm_method': 'information_bottleneck_full',
    'critic_agent': 'rnn_agent_n',
    'critic_lr': 0.0005,
    'critic_mac': 'cate_broadcast_comm_mac_full',
    'cut_mu_rank_thres': 80.0,
    'cut_mu_thres': 1.0,
    'double_q': True,
    'env': 'sc2_tactics',
    'env_args': {   'continuing_episode': False,
                    'debug': False,
                    'difficulty': '7',
                    'game_version': None,
                    'heuristic_ai': False,
                    'heuristic_rest': False,
                    'map_name': 'jdsr',
                    'move_amount': 2,
                    'obs_all_health': True,
                    'obs_instead_of_state': False,
                    'obs_last_action': False,
                    'obs_own_health': True,
                    'obs_pathing_grid': True,
                    'obs_terrain_height': True,
                    'obs_timestep_number': False,
                    'replay_dir': '',
                    'replay_prefix': '',
                    'reward_death_value': 10,
                    'reward_defeat': 0,
                    'reward_negative_scale': 0.5,
                    'reward_only_positive': False,
                    'reward_scale': True,
                    'reward_scale_rate': 20,
                    'reward_sparse': False,
                    'reward_win': 200,
                    'seed': 42,
                    'state_last_action': True,
                    'state_timestep_number': False,
                    'step_mul': 8},
    'epsilon_anneal_time': 100000,
    'epsilon_finish': 0.05,
    'epsilon_start': 0.995,
    'evaluate': False,
    'gamma': 0.99,
    'gate_loss_beta': 1e-05,
    'grad_norm_clip': 10,
    'hysteretic_qmix': True,
    'is_comm_beta_decay': False,
    'is_comm_entropy_beta_decay': False,
    'is_cur_mu': False,
    'is_print': False,
    'is_rank_cut_mu': False,
    'label': 'default_label',
    'learner': 'max_q_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.001,
    'mac': 'basic_mac_logits',
    'mixer': 'transformer_qmix',
    'mixing_embed_dim': 64,
    'name': 'transformer_qmix_env=4_adam_td_lambda',
    'obs_agent_id': True,
    'obs_last_action': True,
    'only_downstream': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'p': 0.5,
    'qmix_loss': 1,
    'repeat_id': 1,
    'rnn_hidden_dim': 64,
    'run': 'default',
    'runner': 'episode',
    'runner_log_interval': 10000,
    'save_model': True,
    'save_model_interval': 500000,
    'save_replay': False,
    'seed': 42,
    't_max': 2005000,
    'target_update_interval': 200,
    'td_lambda': 0.6,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 32,
    'transformer_dropout': 0.1,
    'transformer_ff_dim': 256,
    'transformer_heads': 4,
    'transformer_layers': 2,
    'use_IB': True,
    'use_cuda': True,
    'use_tensorboard': True,
    'w': 0.5}

----------------------
You create a JDSR env!
----------------------
184
Mixer Size: 
363.588K
namespace(runner='episode', mac='basic_mac_logits', env='sc2_tactics', env_args={'continuing_episode': False, 'difficulty': '7', 'game_version': None, 'map_name': 'jdsr', 'move_amount': 2, 'obs_all_health': True, 'obs_instead_of_state': False, 'obs_last_action': False, 'obs_own_health': True, 'obs_pathing_grid': True, 'obs_terrain_height': True, 'obs_timestep_number': False, 'reward_death_value': 10, 'reward_defeat': 0, 'reward_negative_scale': 0.5, 'reward_only_positive': False, 'reward_scale': True, 'reward_scale_rate': 20, 'reward_sparse': False, 'reward_win': 200, 'replay_dir': '', 'replay_prefix': '', 'state_last_action': True, 'state_timestep_number': False, 'step_mul': 8, 'seed': 42, 'heuristic_ai': False, 'heuristic_rest': False, 'debug': False}, batch_size_run=1, test_nepisode=32, test_interval=10000, test_greedy=True, log_interval=10000, runner_log_interval=10000, learner_log_interval=10000, t_max=2005000, use_cuda=True, buffer_cpu_only=True, use_tensorboard=True, save_model=True, save_model_interval=500000, checkpoint_path='', evaluate=False, load_step=0, save_replay=False, local_results_path='results', gamma=0.99, batch_size=128, buffer_size=5000, lr=0.001, critic_lr=0.0005, optim_alpha=0.99, optim_eps=1e-05, grad_norm_clip=10, agent='rnn', rnn_hidden_dim=64, obs_agent_id=True, obs_last_action=True, repeat_id=1, label='default_label', run='default', action_selector='epsilon_greedy', epsilon_start=0.995, epsilon_finish=0.05, epsilon_anneal_time=100000, critic_mac='cate_broadcast_comm_mac_full', critic_agent='rnn_agent_n', comm=True, comm_embed_dim=3, comm_method='information_bottleneck_full', c_beta=1.0, comm_beta=0.001, comm_entropy_beta='1e-6', gate_loss_beta=1e-05, only_downstream=False, use_IB=True, is_print=False, is_comm_beta_decay=False, comm_beta_start_decay=20000000, comm_beta_target='1e-2', comm_beta_end_decay=50000000, is_comm_entropy_beta_decay=False, comm_entropy_beta_start_decay=20000000, comm_entropy_beta_target='1e-4', comm_entropy_beta_end_decay=50000000, is_cur_mu=False, is_rank_cut_mu=False, cut_mu_thres=1.0, cut_mu_rank_thres=80.0, target_update_interval=200, agent_output_type='q', learner='max_q_learner', double_q=True, mixer='transformer_qmix', mixing_embed_dim=64, transformer_heads=4, transformer_layers=2, transformer_ff_dim=256, transformer_dropout=0.1, central_loss=1, qmix_loss=1, w=0.5, hysteretic_qmix=True, central_mixing_embed_dim=256, central_action_embed=1, central_mac='basic_central_mac', central_agent='central_rnn', central_rnn_hidden_dim=64, central_mixer='ff', td_lambda=0.6, alpha_lr='3e-4', alpha_init=-0.07, p=0.5, name='transformer_qmix_env=4_adam_td_lambda', seed=42, device='cuda', unique_token='transformer_qmix_env=4_adam_td_lambda__2025-11-19_14-22-56', n_agents=9, n_actions=10, state_shape=194, accumulated_episodes=None)
[INFO 14:22:58] my_main Beginning training for 2005000 timesteps
[INFO 14:22:58] absl Launching SC2: /share/project/ytz/StarCraftII/Versions/Base75689/SC2_x64 -listen 127.0.0.1 -port 45161 -dataDir /share/project/ytz/StarCraftII/ -tempDir /tmp/sc-4j8ins_o/
[INFO 14:22:58] absl Connecting to: ws://127.0.0.1:45161/sc2api, attempt: 0, running: True
Version: B75689 (SC2.4.10)
Build: Aug 12 2019 17:16:57
Command Line: '"/share/project/ytz/StarCraftII/Versions/Base75689/SC2_x64" -listen 127.0.0.1 -port 45161 -dataDir /share/project/ytz/StarCraftII/ -tempDir /tmp/sc-4j8ins_o/'
Starting up...
Startup Phase 1 complete
[INFO 14:22:59] absl Connecting to: ws://127.0.0.1:45161/sc2api, attempt: 1, running: True
Startup Phase 2 complete
Creating stub renderer...
Listening on: 127.0.0.1:45161
Startup Phase 3 complete. Ready for commands.
[INFO 14:23:00] absl Connecting to: ws://127.0.0.1:45161/sc2api, attempt: 2, running: True
ConnectHandler: Request from 127.0.0.1:44108 accepted
ReadyHandler: 127.0.0.1:44108 ready
Requesting to join a single player game
Configuring interface options
Configure: raw interface enabled
Configure: feature layer interface disabled
Configure: score interface disabled
Configure: render interface disabled
Launching next game.
Next launch phase started: 2
Next launch phase started: 3
Next launch phase started: 4
Next launch phase started: 5
Next launch phase started: 6
Next launch phase started: 7
Next launch phase started: 8
Game has started.
Using default stable ids, none found at: /share/project/ytz/StarCraftII/stableid.json
Successfully loaded stable ids: GameData\stableid.json
Sending ResponseJoinGame
{'roach': 110, 'infestor': 111, 'stalker': 74, 'colossus': 4}
/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/components/episode_buffer.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)
  v = th.tensor(v, dtype=dtype, device=self.device)
/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/components/episode_buffer.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  v = th.tensor(v, dtype=dtype, device=self.device)
[INFO 14:23:07] my_main t_env: 64 / 2005000
[INFO 14:23:07] my_main Estimated time left: 32 minutes, 2 seconds. Time passed: 9 seconds
[INFO 14:23:44] my_main Saving models to results/models/transformer_qmix_env=4_adam_td_lambda__2025-11-19_14-22-56/64
[INFO 14:27:50] my_main Recent Stats | t_env:      10011 | Episode:      160
alpha:                     0.9323	alpha_loss:               -6.8281	battle_won_mean:           0.0000	central_loss:              0.0310
comm_loss:                 0.2957	dead_allies_mean:          5.0000	dead_enemies_mean:         0.0000	delta_ally_mean:         335.0000
delta_deaths_mean:       -25.0000	delta_enemy_mean:        160.3750	ep_length_mean:           64.0000	epsilon:                   0.9950
grad_norm:                 0.3822	loss:                      0.3729	mixer_norm:                0.2824	policy_loss:               0.0886
q_taken_mean:              0.0112	qmix_loss:                 0.0462	reward_mean:              -3.7313	reward_std:                0.0000
target_mean:               0.0105	td_error_abs:              0.1965	test_battle_won_mean:      0.0000	test_dead_allies_mean:     5.0000
test_dead_enemies_mean:    0.0000	test_delta_ally_mean:    341.9531	test_delta_deaths_mean:  -25.0000	test_delta_enemy_mean:    29.5000
test_ep_length_mean:      77.6562	test_reward_mean:         -6.3075	test_reward_std:           0.7690	w_to_use:                  0.6994

[INFO 14:27:53] my_main t_env: 10072 / 2005000
[INFO 14:27:53] my_main Estimated time left: 15 hours, 49 minutes, 47 seconds. Time passed: 4 minutes, 55 seconds
[INFO 14:30:20] my_main Updated target network
/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/sacred/stdout_capturing.py:179: UserWarning: tee_stdout.wait timeout. Forcibly terminating.
  warnings.warn("tee_stdout.wait timeout. Forcibly terminating.")
/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/sacred/stdout_capturing.py:185: UserWarning: tee_stderr.wait timeout. Forcibly terminating.
  warnings.warn("tee_stderr.wait timeout. Forcibly terminating.")
[DEBUG 14:30:37] pymarl Stopping Heartbeat
[ERROR 14:30:37] pymarl Failed after 0:07:41!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/main.py", line 53, in my_main
    run_REGISTRY[_config['run']](_run, config, _log)
  File "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/run/run.py", line 54, in run
    run_sequential(args=args, logger=logger)
  File "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/run/run.py", line 197, in run_sequential
    learner.train(episode_sample, runner.t_env, episode)
  File "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/learners/max_q_learner.py", line 316, in train
    comm_loss *= self.args.c_beta *0.01
  File "/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacty of 79.11 GiB of which 23.75 MiB is free. Process 912496 has 940.00 MiB memory in use. Process 912216 has 44.16 GiB memory in use. Process 912673 has 934.00 MiB memory in use. Process 913034 has 930.00 MiB memory in use. Process 913539 has 2.20 GiB memory in use. Process 916282 has 13.78 GiB memory in use. Process 916938 has 942.00 MiB memory in use. Process 918117 has 944.00 MiB memory in use. Process 917394 has 908.00 MiB memory in use. Process 918518 has 11.57 GiB memory in use. Process 918945 has 936.00 MiB memory in use. Process 921603 has 942.00 MiB memory in use. Of the allocated memory 12.16 GiB is allocated by PyTorch, and 536.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[INFO 14:30:37] absl Shutdown gracefully.
[INFO 14:30:37] absl Shutdown with return code: -15

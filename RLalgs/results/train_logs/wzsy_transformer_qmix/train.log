/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/sacred/dependencies.py:11: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
[DEBUG 14:23:23] git.cmd Popen(['git', 'version'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:23:23] git.cmd Popen(['git', 'version'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:23:23] git.util sys.platform='linux', git_executable='git'
[DEBUG 14:23:23] git.cmd Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:23:23] git.cmd Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:23:24] git.cmd Popen(['git', 'cat-file', '--batch-check'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=<valid stream>, shell=False, universal_newlines=False)
[DEBUG 14:23:24] git.util sys.platform='linux', git_executable='git'
[DEBUG 14:23:24] git.cmd Popen(['git', 'diff', '--cached', '--abbrev=40', '--full-index', '--raw'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:23:24] git.cmd Popen(['git', 'diff', '--abbrev=40', '--full-index', '--raw'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=None, shell=False, universal_newlines=False)
[DEBUG 14:23:24] git.cmd Popen(['git', 'cat-file', '--batch-check'], cwd=/share/project/ytz/RLproject/StarCraft2_HLSMAC, stdin=<valid stream>, shell=False, universal_newlines=False)
[INFO 14:23:24] root Saving to FileStorageObserver in /share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/results/sacred/wzsy/transformer_qmix_env=4_adam_td_lambda.
[DEBUG 14:23:26] pymarl Using capture mode "fd"
[INFO 14:23:26] pymarl Running command 'my_main'
[INFO 14:23:26] pymarl Started run with ID "8"
[DEBUG 14:23:26] pymarl Starting Heartbeat
[DEBUG 14:23:26] my_main Started
[INFO 14:23:26] my_main Experiment Parameters:
[INFO 14:23:26] my_main 

{   'action_selector': 'epsilon_greedy',
    'agent': 'rnn',
    'agent_output_type': 'q',
    'alpha_init': -0.07,
    'alpha_lr': '3e-4',
    'batch_size': 128,
    'batch_size_run': 1,
    'buffer_cpu_only': True,
    'buffer_size': 5000,
    'c_beta': 1.0,
    'central_action_embed': 1,
    'central_agent': 'central_rnn',
    'central_loss': 1,
    'central_mac': 'basic_central_mac',
    'central_mixer': 'ff',
    'central_mixing_embed_dim': 256,
    'central_rnn_hidden_dim': 64,
    'checkpoint_path': '',
    'comm': True,
    'comm_beta': 0.001,
    'comm_beta_end_decay': 50000000,
    'comm_beta_start_decay': 20000000,
    'comm_beta_target': '1e-2',
    'comm_embed_dim': 3,
    'comm_entropy_beta': '1e-6',
    'comm_entropy_beta_end_decay': 50000000,
    'comm_entropy_beta_start_decay': 20000000,
    'comm_entropy_beta_target': '1e-4',
    'comm_method': 'information_bottleneck_full',
    'critic_agent': 'rnn_agent_n',
    'critic_lr': 0.0005,
    'critic_mac': 'cate_broadcast_comm_mac_full',
    'cut_mu_rank_thres': 80.0,
    'cut_mu_thres': 1.0,
    'double_q': True,
    'env': 'sc2_tactics',
    'env_args': {   'continuing_episode': False,
                    'debug': False,
                    'difficulty': '7',
                    'game_version': None,
                    'heuristic_ai': False,
                    'heuristic_rest': False,
                    'map_name': 'wzsy',
                    'move_amount': 2,
                    'obs_all_health': True,
                    'obs_instead_of_state': False,
                    'obs_last_action': False,
                    'obs_own_health': True,
                    'obs_pathing_grid': True,
                    'obs_terrain_height': True,
                    'obs_timestep_number': False,
                    'replay_dir': '',
                    'replay_prefix': '',
                    'reward_death_value': 10,
                    'reward_defeat': 0,
                    'reward_negative_scale': 0.5,
                    'reward_only_positive': False,
                    'reward_scale': True,
                    'reward_scale_rate': 20,
                    'reward_sparse': False,
                    'reward_win': 200,
                    'seed': 42,
                    'state_last_action': True,
                    'state_timestep_number': False,
                    'step_mul': 8},
    'epsilon_anneal_time': 100000,
    'epsilon_finish': 0.05,
    'epsilon_start': 0.995,
    'evaluate': False,
    'gamma': 0.99,
    'gate_loss_beta': 1e-05,
    'grad_norm_clip': 10,
    'hysteretic_qmix': True,
    'is_comm_beta_decay': False,
    'is_comm_entropy_beta_decay': False,
    'is_cur_mu': False,
    'is_print': False,
    'is_rank_cut_mu': False,
    'label': 'default_label',
    'learner': 'max_q_learner',
    'learner_log_interval': 10000,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.001,
    'mac': 'basic_mac_logits',
    'mixer': 'transformer_qmix',
    'mixing_embed_dim': 64,
    'name': 'transformer_qmix_env=4_adam_td_lambda',
    'obs_agent_id': True,
    'obs_last_action': True,
    'only_downstream': False,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'p': 0.5,
    'qmix_loss': 1,
    'repeat_id': 1,
    'rnn_hidden_dim': 64,
    'run': 'default',
    'runner': 'episode',
    'runner_log_interval': 10000,
    'save_model': True,
    'save_model_interval': 500000,
    'save_replay': False,
    'seed': 42,
    't_max': 2005000,
    'target_update_interval': 200,
    'td_lambda': 0.6,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 32,
    'transformer_dropout': 0.1,
    'transformer_ff_dim': 256,
    'transformer_heads': 4,
    'transformer_layers': 2,
    'use_IB': True,
    'use_cuda': True,
    'use_tensorboard': True,
    'w': 0.5}

----------------------
You create a WZSY env!
----------------------
302
Mixer Size: 
478.404K
namespace(runner='episode', mac='basic_mac_logits', env='sc2_tactics', env_args={'continuing_episode': False, 'difficulty': '7', 'game_version': None, 'map_name': 'wzsy', 'move_amount': 2, 'obs_all_health': True, 'obs_instead_of_state': False, 'obs_last_action': False, 'obs_own_health': True, 'obs_pathing_grid': True, 'obs_terrain_height': True, 'obs_timestep_number': False, 'reward_death_value': 10, 'reward_defeat': 0, 'reward_negative_scale': 0.5, 'reward_only_positive': False, 'reward_scale': True, 'reward_scale_rate': 20, 'reward_sparse': False, 'reward_win': 200, 'replay_dir': '', 'replay_prefix': '', 'state_last_action': True, 'state_timestep_number': False, 'step_mul': 8, 'seed': 42, 'heuristic_ai': False, 'heuristic_rest': False, 'debug': False}, batch_size_run=1, test_nepisode=32, test_interval=10000, test_greedy=True, log_interval=10000, runner_log_interval=10000, learner_log_interval=10000, t_max=2005000, use_cuda=True, buffer_cpu_only=True, use_tensorboard=True, save_model=True, save_model_interval=500000, checkpoint_path='', evaluate=False, load_step=0, save_replay=False, local_results_path='results', gamma=0.99, batch_size=128, buffer_size=5000, lr=0.001, critic_lr=0.0005, optim_alpha=0.99, optim_eps=1e-05, grad_norm_clip=10, agent='rnn', rnn_hidden_dim=64, obs_agent_id=True, obs_last_action=True, repeat_id=1, label='default_label', run='default', action_selector='epsilon_greedy', epsilon_start=0.995, epsilon_finish=0.05, epsilon_anneal_time=100000, critic_mac='cate_broadcast_comm_mac_full', critic_agent='rnn_agent_n', comm=True, comm_embed_dim=3, comm_method='information_bottleneck_full', c_beta=1.0, comm_beta=0.001, comm_entropy_beta='1e-6', gate_loss_beta=1e-05, only_downstream=False, use_IB=True, is_print=False, is_comm_beta_decay=False, comm_beta_start_decay=20000000, comm_beta_target='1e-2', comm_beta_end_decay=50000000, is_comm_entropy_beta_decay=False, comm_entropy_beta_start_decay=20000000, comm_entropy_beta_target='1e-4', comm_entropy_beta_end_decay=50000000, is_cur_mu=False, is_rank_cut_mu=False, cut_mu_thres=1.0, cut_mu_rank_thres=80.0, target_update_interval=200, agent_output_type='q', learner='max_q_learner', double_q=True, mixer='transformer_qmix', mixing_embed_dim=64, transformer_heads=4, transformer_layers=2, transformer_ff_dim=256, transformer_dropout=0.1, central_loss=1, qmix_loss=1, w=0.5, hysteretic_qmix=True, central_mixing_embed_dim=256, central_action_embed=1, central_mac='basic_central_mac', central_agent='central_rnn', central_rnn_hidden_dim=64, central_mixer='ff', td_lambda=0.6, alpha_lr='3e-4', alpha_init=-0.07, p=0.5, name='transformer_qmix_env=4_adam_td_lambda', seed=42, device='cuda', unique_token='transformer_qmix_env=4_adam_td_lambda__2025-11-19_14-23-26', n_agents=12, n_actions=17, state_shape=392, accumulated_episodes=None)
[INFO 14:23:30] my_main Beginning training for 2005000 timesteps
[INFO 14:23:30] absl Launching SC2: /share/project/ytz/StarCraftII/Versions/Base75689/SC2_x64 -listen 127.0.0.1 -port 37173 -dataDir /share/project/ytz/StarCraftII/ -tempDir /tmp/sc-xg2dlghq/
[INFO 14:23:30] absl Connecting to: ws://127.0.0.1:37173/sc2api, attempt: 0, running: True
Version: B75689 (SC2.4.10)
Build: Aug 12 2019 17:16:57
Command Line: '"/share/project/ytz/StarCraftII/Versions/Base75689/SC2_x64" -listen 127.0.0.1 -port 37173 -dataDir /share/project/ytz/StarCraftII/ -tempDir /tmp/sc-xg2dlghq/'
Starting up...
Startup Phase 1 complete
[INFO 14:23:31] absl Connecting to: ws://127.0.0.1:37173/sc2api, attempt: 1, running: True
Startup Phase 2 complete
Creating stub renderer...
[INFO 14:23:32] absl Connecting to: ws://127.0.0.1:37173/sc2api, attempt: 2, running: True
Listening on: 127.0.0.1:37173
Startup Phase 3 complete. Ready for commands.
[INFO 14:23:33] absl Connecting to: ws://127.0.0.1:37173/sc2api, attempt: 3, running: True
ConnectHandler: Request from 127.0.0.1:37808 accepted
ReadyHandler: 127.0.0.1:37808 ready
Requesting to join a single player game
Configuring interface options
Configure: raw interface enabled
Configure: feature layer interface disabled
Configure: score interface disabled
Configure: render interface disabled
Launching next game.
Next launch phase started: 2
Next launch phase started: 3
Next launch phase started: 4
Next launch phase started: 5
Next launch phase started: 6
Next launch phase started: 7
Next launch phase started: 8
Game has started.
Using default stable ids, none found at: /share/project/ytz/StarCraftII/stableid.json
Successfully loaded stable ids: GameData\stableid.json
Sending ResponseJoinGame
{'stalker': 74, 'sentry': 77}
/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/components/episode_buffer.py:103: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:261.)
  v = th.tensor(v, dtype=dtype, device=self.device)
/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/components/episode_buffer.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  v = th.tensor(v, dtype=dtype, device=self.device)
[INFO 14:23:42] my_main t_env: 198 / 2005000
[INFO 14:23:42] my_main Estimated time left: 40 minutes, 36 seconds. Time passed: 12 seconds
[INFO 14:26:05] my_main Saving models to results/models/transformer_qmix_env=4_adam_td_lambda__2025-11-19_14-23-26/198
[INFO 14:30:32] my_main Recent Stats | t_env:      10189 | Episode:       54
battle_won_mean:           0.0000	dead_allies_mean:         12.0000	dead_enemies_mean:         0.0000	delta_ally_mean:         320.0000
delta_deaths_mean:       -30.0000	delta_enemy_mean:         89.3750	ep_length_mean:          198.0000	epsilon:                   0.9950
reward_mean:              -1.1983	reward_std:                0.0000	test_battle_won_mean:      0.0000	test_dead_allies_mean:    12.0000
test_dead_enemies_mean:    0.6875	test_delta_ally_mean:    320.0000	test_delta_deaths_mean:  -23.1250	test_delta_enemy_mean:   219.0312
test_ep_length_mean:     193.4062	test_reward_mean:         -0.5705	test_reward_std:           0.1677	
[INFO 14:30:37] my_main t_env: 10387 / 2005000
[INFO 14:30:37] my_main Estimated time left: 22 hours, 31 minutes, 45 seconds. Time passed: 7 minutes, 6 seconds
[INFO 14:35:07] my_main Recent Stats | t_env:      20246 | Episode:      107
battle_won_mean:           0.0000	dead_allies_mean:         12.0000	dead_enemies_mean:         0.0000	delta_ally_mean:         320.0000
delta_deaths_mean:       -30.0000	delta_enemy_mean:        142.0579	ep_length_mean:          188.6852	epsilon:                   0.8987
reward_mean:              -0.9561	reward_std:                0.1394	test_battle_won_mean:      0.0000	test_dead_allies_mean:    12.0000
test_dead_enemies_mean:    0.6250	test_delta_ally_mean:    320.0000	test_delta_deaths_mean:  -23.7500	test_delta_enemy_mean:   215.5000
test_ep_length_mean:     193.8125	test_reward_mean:         -0.5897	test_reward_std:           0.1886	
[INFO 14:35:10] my_main t_env: 20436 / 2005000
[INFO 14:35:10] my_main Estimated time left: 14 hours, 59 minutes, 56 seconds. Time passed: 11 minutes, 40 seconds
[INFO 14:41:46] my_main Recent Stats | t_env:      30414 | Episode:      162
alpha:                     0.9323	alpha_loss:              -15.3227	battle_won_mean:           0.0000	central_loss:              0.0016
comm_loss:                 0.3554	dead_allies_mean:         12.0000	dead_enemies_mean:         0.0000	delta_ally_mean:         320.0000
delta_deaths_mean:       -30.0000	delta_enemy_mean:        159.8349	ep_length_mean:          189.6038	epsilon:                   0.8037
grad_norm:                 0.7895	loss:                      0.3820	mixer_norm:                0.7787	policy_loss:              -0.0529
q_taken_mean:             -0.0044	qmix_loss:                 0.0250	reward_mean:              -0.8743	reward_std:                0.1182
target_mean:               0.0079	td_error_abs:              0.1519	test_battle_won_mean:      0.0000	test_dead_allies_mean:    12.0000
test_dead_enemies_mean:    0.5312	test_delta_ally_mean:    320.0000	test_delta_deaths_mean:  -24.6875	test_delta_enemy_mean:   214.1875
test_ep_length_mean:     194.0938	test_reward_mean:         -0.6000	test_reward_std:           0.1845	w_to_use:                  0.9838

[INFO 14:41:57] my_main t_env: 30600 / 2005000
[INFO 14:41:57] my_main Estimated time left: 21 hours, 57 minutes, 26 seconds. Time passed: 18 minutes, 27 seconds
/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/sacred/stdout_capturing.py:179: UserWarning: tee_stdout.wait timeout. Forcibly terminating.
  warnings.warn("tee_stdout.wait timeout. Forcibly terminating.")
/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/sacred/stdout_capturing.py:185: UserWarning: tee_stderr.wait timeout. Forcibly terminating.
  warnings.warn("tee_stderr.wait timeout. Forcibly terminating.")
[DEBUG 14:43:54] pymarl Stopping Heartbeat
[ERROR 14:43:54] pymarl Failed after 0:20:28!
Traceback (most recent calls WITHOUT Sacred internals):
  File "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/main.py", line 53, in my_main
    run_REGISTRY[_config['run']](_run, config, _log)
  File "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/run/run.py", line 54, in run
    run_sequential(args=args, logger=logger)
  File "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/run/run.py", line 197, in run_sequential
    learner.train(episode_sample, runner.t_env, episode)
  File "/share/project/ytz/RLproject/StarCraft2_HLSMAC/RLalgs/TransformerMixer/src/learners/max_q_learner.py", line 307, in train
    label_prob = th.gather(logits_out, 3, label_target_actions).squeeze(3)
  File "/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/distributions/kl.py", line 191, in kl_divergence
    return fun(p, q)
  File "/root/miniconda3/envs/py310_sc2/lib/python3.10/site-packages/torch/distributions/kl.py", line 469, in _kl_normal_normal
    return 0.5 * (var_ratio + t1 - 1 - var_ratio.log())
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 44.00 MiB. GPU 0 has a total capacty of 79.11 GiB of which 29.81 MiB is free. Process 913034 has 24.93 GiB memory in use. Process 918117 has 3.84 GiB memory in use. Process 918945 has 50.28 GiB memory in use. Of the allocated memory 48.88 GiB is allocated by PyTorch, and 318.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF

[INFO 14:43:54] absl Shutdown gracefully.
[INFO 14:43:54] absl Shutdown with return code: -15

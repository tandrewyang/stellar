# Curriculum Learning 优化介绍

## 核心思路

在 dTAPE 基础上，通过**课程学习（Curriculum Learning）**策略，从简单任务开始，逐步增加任务难度，使智能体能够更好地学习和适应复杂任务。

## dTAPE 基线的问题

dTAPE 采用**固定难度训练**：
- 智能体从一开始就面对完整难度的任务
- 对于复杂任务，智能体可能无法获得有效的学习信号
- 训练初期失败率高，学习效率低

**局限性**：
- 复杂任务的学习曲线陡峭，初期难以获得正反馈
- 稀疏奖励导致学习信号不足
- 难以建立基础技能，直接面对复杂策略

## Curriculum Learning 的改进

### 1. 渐进式难度调度

**核心机制**：从简单任务开始，逐步增加难度

```
训练开始 (难度 = 0.0)
    ↓
逐步增加难度 (0.0 → 1.0)
    ↓
训练结束 (难度 = 1.0，完整任务)
```

**两种调度方式**：

1. **线性调度（Linear Schedule）**
   ```
   难度 = min_difficulty + (max_difficulty - min_difficulty) * 训练进度
   ```
   - 根据训练步数线性增加难度
   - 平滑过渡，避免突然变化

2. **自适应调度（Adaptive Schedule）**
   - 基于智能体性能动态调整
   - 胜率 > 80%：增加难度
   - 胜率 < 20%：降低难度
   - 确保智能体始终在合适的难度下学习

### 2. 技术实现

**关键参数**：
- `curriculum_enabled`: True - 启用课程学习
- `curriculum_schedule`: "linear" - 调度方式（linear/adaptive）
- `curriculum_start_step`: 0 - 开始课程学习的步数
- `curriculum_end_step`: 1000000 - 结束课程学习的步数
- `curriculum_min_difficulty`: 0.0 - 最小难度（最简单）
- `curriculum_max_difficulty`: 1.0 - 最大难度（完整任务）

**实现流程**：
```python
# 每个训练步骤
1. 更新课程难度（根据训练进度或性能）
2. 应用难度到训练batch
3. 训练模型
4. 记录课程信息
```

### 3. 与 dTAPE 的对比

| 特性 | dTAPE | Curriculum Learning |
|------|-------|-------------------|
| **任务难度** | 固定（完整难度） | 逐步增加（0.0 → 1.0） |
| **初始学习** | 直接面对困难任务 | 从简单任务开始 |
| **学习曲线** | 可能陡峭，初期困难 | 更平滑，渐进式 |
| **收敛速度** | 中等 | 更快（避免初期失败） |
| **训练稳定性** | 中等 | 更高（逐步建立技能） |
| **最终性能** | 基准 | 可能更高 |

## 优势

1. **更好的学习曲线**：从简单到复杂，学习更稳定
2. **更快的收敛**：避免一开始就面对困难任务，减少无效探索
3. **更高的成功率**：逐步建立技能，最终完成复杂任务
4. **自适应调整**：可以根据性能动态调整难度，确保始终在合适的难度下学习

## 实现要点

- 保持 dTAPE 的核心算法（QMIX Mixer、Central Q、通信机制）不变
- 仅改进训练策略，通过难度调度优化学习过程
- 模块化设计，易于扩展和调优

